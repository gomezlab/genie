{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--drug', type=str, default='egfr')\n",
    "parser.add_argument('--outcome', type=str, default='OS')\n",
    "parser.add_argument('--data_type', type=str, default='comb')\n",
    "parser.add_argument('--lasso_c', type=str, default=2)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "drug = args.drug\n",
    "outcome = args.outcome\n",
    "data_type = args.data_type\n",
    "lasso_c = args.lasso_c\n",
    "lasso_c = float(lasso_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug = 'folfox'\n",
    "outcome = 'PFS'\n",
    "data_type = 'nonclin'\n",
    "lasso_c = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-22 15:48:08.656212: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-22 15:48:08.708658: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-22 15:48:08.709757: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-22 15:48:09.534907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drug: folfox, outcome: PFS, data_type: nonclin\n",
      "X_train shape: (782, 238), X_test shape: (189, 238)\n",
      "y_train shape: (782,), y_test shape: (189,)\n",
      "X_train shape: (781, 236), X_test shape: (190, 236)\n",
      "y_train shape: (781,), y_test shape: (190,)\n",
      "X_train shape: (775, 235), X_test shape: (196, 235)\n",
      "y_train shape: (775,), y_test shape: (196,)\n",
      "X_train shape: (769, 241), X_test shape: (202, 241)\n",
      "y_train shape: (769,), y_test shape: (202,)\n",
      "X_train shape: (777, 221), X_test shape: (194, 221)\n",
      "y_train shape: (777,), y_test shape: (194,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "today = datetime.date.today()\n",
    "today_str = today.strftime('%m%d%y')\n",
    "\n",
    "\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, roc_auc_score, roc_curve, auc\n",
    "from math import sqrt\n",
    "\n",
    "#calculate auprc 95% ci for each model\n",
    "def auroc_ci(y_true, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    mean = roc_auc\n",
    "    std = sqrt(roc_auc * (1.0 - roc_auc) / len(y_true))\n",
    "    low  = mean - std\n",
    "    high = mean + std\n",
    "    return low, mean, high\n",
    "\n",
    "def auprc_ci(y_true, y_pred):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    mean = pr_auc\n",
    "    std = sqrt(pr_auc * (1.0 - pr_auc) / len(y_true))\n",
    "    low  = mean - std\n",
    "    high = mean + std\n",
    "    return low, mean, high\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_score, StratifiedGroupKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tensorflow import keras\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "\n",
    "print('drug: {}, outcome: {}, data_type: {}'.format(drug, outcome, data_type))\n",
    "\n",
    "data = pd.read_csv('../../data/crc_{}_mut_cna_fus_clin.csv'.format(drug))\n",
    "data.rename(columns={'Unnamed: 0': 'id'}, inplace=True)\n",
    "data = data.dropna(subset=[outcome])\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#test set is VICC\n",
    "# X_train = data[data['id_institution'].isin(['DFCI', 'MSKCC'])]\n",
    "# y = train[outcome]\n",
    "# X_test = data[data['id_institution'] == 'VICC']\n",
    "# y_test = test[outcome]\n",
    "\n",
    "#create 5 train, test splits, within each train, create 5 train, valid splits\n",
    "skf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "groups = data['id']\n",
    "X = data[[col for col in data.columns if 'mut_' in col or 'cna_' in col or 'clin_' in col or 'fus' in col]]\n",
    "y = data[outcome]\n",
    "\n",
    "input_shape = [X.shape[1]]\n",
    "\n",
    "def build_model(n_hidden=1, n_neurons=100, dropout=0.4, activation = \"relu\", learning_rate=3e-3):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Flatten(input_shape=input_shape))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "        model.add(keras.layers.Activation(activation))\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", metrics=['AUC'], optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "res_df = pd.DataFrame(columns=['fold', 'val_auroc_mean', 'val_auroc_ci', 'test_auroc_mean', 'test_auprc_mean'])\n",
    "fold_count = 0\n",
    "for train_index, test_index in skf.split(X, y, groups):\n",
    "    X_train = X.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "\n",
    "    # #move all the samples in X_test, where clin_stage_dx is 0 to X_train\n",
    "    # mov_test_idxs = X_test[X_test['clin_stage_dx_iv'] == 0].index\n",
    "\n",
    "    # X_train = pd.concat([X_train, X_test.loc[mov_test_idxs]])\n",
    "    # X_test = X_test[X_test['clin_stage_dx_iv'] == 1]\n",
    "    # use mov_test_idxs to move the y_test values to y_train\n",
    "    # y_train = pd.concat([y_train, y_test.loc[mov_test_idxs]])\n",
    "    # y_test.drop(mov_test_idxs, inplace=True)\n",
    "    # #now get a sample of X_train of the same len as mov_test_idxs, where clin_stage_dx_iv == 1\n",
    "    # X_1_samp = X_train[X_train['clin_stage_dx_iv'] == 1].sample(n=len(mov_test_idxs), random_state=1)\n",
    "    # y_1_samp = y_train.loc[X_1_samp.index]\n",
    "    # X_test = pd.concat([X_test, X_1_samp])\n",
    "    # y_test = pd.concat([y_test, y_1_samp])\n",
    "    # X_train.drop(X_1_samp.index, inplace=True)\n",
    "    # y_train.drop(X_1_samp.index, inplace=True)\n",
    "\n",
    "\n",
    "    if (data_type != 'comb') & (data_type != 'nonclin'):\n",
    "        X_train = X_train[[col for col in data.columns if '{}_'.format(data_type) in col]]\n",
    "        X_test = X_test[[col for col in data.columns if '{}_'.format(data_type) in col]]\n",
    "    elif data_type == 'nonclin':\n",
    "        X_train = X_train[[col for col in data.columns if 'mut_' in col or 'cna_' in col or 'fus' in col]]\n",
    "        X_test = X_test[[col for col in data.columns if 'mut_' in col or 'cna_' in col or 'fus' in col]]\n",
    "    else:\n",
    "        X_train = X_train[[col for col in data.columns if 'mut_' in col or 'cna_' in col or 'clin_' in col or 'fus' in col]]\n",
    "        X_test = X_test[[col for col in data.columns if 'mut_' in col or 'cna_' in col or 'clin_' in col or 'fus' in col]]\n",
    "\n",
    "    #use lasso to select features\n",
    "    lasso = LogisticRegression(penalty='l1', C=lasso_c, solver='liblinear')\n",
    "    lasso.fit(X_train, y_train)\n",
    "    lasso_coef = lasso.coef_\n",
    "    lasso_coef = lasso_coef[0]\n",
    "    lasso_coef = pd.DataFrame({'feature': X_train.columns, 'coef': lasso_coef})\n",
    "    lasso_coef = lasso_coef[lasso_coef['coef'] != 0]\n",
    "    X_train = X_train[lasso_coef['feature']]\n",
    "    X_test = X_test[lasso_coef['feature']]\n",
    "    \n",
    "    print('X_train shape: {}, X_test shape: {}'.format(X_train.shape, X_test.shape))\n",
    "    print('y_train shape: {}, y_test shape: {}'.format(y_train.shape, y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Number of trees in random forest\n",
    "    n_estimators = [500, 750, 1000, 1250, 1500]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto','sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [20, 40, 60, 80, 100, 120]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 3, 4, 6]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [2, 4, 6, 8]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True]\n",
    "\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'bootstrap': bootstrap}\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    rf_random = BayesSearchCV(rf, random_grid, n_iter = 150, cv = 5, verbose=2, scoring='roc_auc', random_state=42, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X_train, y_train)\n",
    "\n",
    "    results = pd.DataFrame(rf_random.cv_results_)\n",
    "    results.sort_values(by='rank_test_score').to_csv('../../results/hp_search/results_rf_lasso_{}_{}_{}_{}_{}.csv'.format(drug, outcome, data_type, today_str, fold_count))\n",
    "    best_rf = rf_random.best_estimator_\n",
    "\n",
    "    y_pred = best_rf.predict_proba(X_test)[:,1]\n",
    "        \n",
    "    test_auroc_mean = roc_auc_score(y_test, y_pred)\n",
    "        \n",
    "    test_auprc_mean = average_precision_score(y_test, y_pred)\n",
    "\n",
    "    val_auroc = rf_random.best_score_\n",
    "    val_auroc_mean = val_auroc\n",
    "    val_auroc_std = str(val_auroc - results['std_test_score'][rf_random.best_index_]) + '-' + str(val_auroc + results['std_test_score'][rf_random.best_index_])\n",
    "    val_auroc_ci = str(val_auroc - 2*results['std_test_score'][rf_random.best_index_]) + '-' + str(val_auroc + 2*results['std_test_score'][rf_random.best_index_])\n",
    "    res_df.loc[fold_count] = [fold_count, val_auroc_mean, val_auroc_ci, test_auroc_mean, test_auprc_mean]\n",
    "\n",
    "    del rf_random\n",
    "    del best_rf\n",
    "\n",
    "    fold_count += 1\n",
    "\n",
    "out_folder = '../../results/lasso_runs/{}'.format(today_str)\n",
    "#if out_folder does not exist, create it\n",
    "if not os.path.exists(out_folder):\n",
    "    os.mkdir(out_folder)\n",
    "    res_df.to_csv('../../results/lasso_runs/{}/results_rf_{}_{}_{}_{}.csv'.format(today_str, drug, outcome, data_type, today_str))\n",
    "else:\n",
    "    res_df.to_csv('../../results/lasso_runs/{}/results_rf_{}_{}_{}_{}.csv'.format(today_str, drug, outcome, data_type, today_str))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
